{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1: Spread Pattern Analysis - Bot vs Human Misinformation\n",
    "\n",
    "## Research Question\n",
    "**What are the differences in how misinformation spreads on social media when driven by bots compared to when driven by human users?**\n",
    "\n",
    "### Analysis Focus\n",
    "1. Speed of spread (temporal dynamics)\n",
    "2. Audience reach and size\n",
    "3. Network structure of propagation\n",
    "4. Cascading patterns and virality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from analysis.rq1_spread_patterns import RQ1Analyzer\n",
    "from utils.metrics import *\n",
    "from utils.visualization import *\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Integrated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load integrated dataset\n",
    "DATA_PATH = Path('../data/processed/integrated_dataset.parquet')\n",
    "\n",
    "if DATA_PATH.exists():\n",
    "    df = pd.read_parquet(DATA_PATH)\n",
    "    print(f\"Loaded {len(df)} records\")\n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Display basic statistics\n",
    "    print(\"\\nBasic Statistics:\")\n",
    "    print(f\"- Unique users: {df['user_id'].nunique()}\")\n",
    "    print(f\"- Bot posts: {(df['bot_label'] == 'bot').sum()}\")\n",
    "    print(f\"- Human posts: {(df['bot_label'] == 'human').sum()}\")\n",
    "    print(f\"- Fake news posts: {(df['label'] == 'fake').sum()}\")\n",
    "    print(f\"- Real news posts: {(df['label'] == 'real').sum()}\")\n",
    "else:\n",
    "    print(f\"Dataset not found at {DATA_PATH}\")\n",
    "    print(\"Please run data integration pipeline first.\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize RQ1 Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    analyzer = RQ1Analyzer(df)\n",
    "    print(\"RQ1 Analyzer initialized successfully\")\n",
    "else:\n",
    "    print(\"Cannot initialize analyzer without data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 1: Speed of Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate cascades\n",
    "if df is not None:\n",
    "    bot_cascades, human_cascades = analyzer.separate_cascades()\n",
    "    \n",
    "    # Analyze spread speed\n",
    "    speed_results = analyzer.analyze_spread_speed(bot_cascades, human_cascades)\n",
    "    \n",
    "    print(\"\\nSpeed Analysis Results:\")\n",
    "    for key, value in speed_results.items():\n",
    "        print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 2: Audience Reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze reach\n",
    "if df is not None:\n",
    "    reach_results = analyzer.analyze_reach(bot_cascades, human_cascades)\n",
    "    \n",
    "    print(\"\\nReach Analysis Results:\")\n",
    "    for key, value in reach_results.items():\n",
    "        print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 3: Temporal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temporal patterns\n",
    "if df is not None:\n",
    "    temporal_results = analyzer.analyze_temporal_patterns()\n",
    "    \n",
    "    print(\"\\nTemporal Analysis Results:\")\n",
    "    for key, value in temporal_results.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cascade size distribution\n",
    "if df is not None:\n",
    "    bot_sizes = [len(c) for c in bot_cascades]\n",
    "    human_sizes = [len(c) for c in human_cascades]\n",
    "    \n",
    "    plot_cascade_size_distribution(\n",
    "        bot_sizes, human_sizes,\n",
    "        save_path='../results/figures/rq1_cascade_sizes.png'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal posting patterns\n",
    "if df is not None and 'timestamp' in df.columns:\n",
    "    plot_temporal_patterns(\n",
    "        df, time_col='timestamp', bot_label_col='bot_label',\n",
    "        window='1H',\n",
    "        save_path='../results/figures/rq1_temporal_patterns.png'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "if df is not None:\n",
    "    # Mann-Whitney U test for cascade sizes\n",
    "    u_stat, p_value = stats.mannwhitneyu(bot_sizes, human_sizes, alternative='two-sided')\n",
    "    \n",
    "    print(\"Statistical Test: Cascade Size Difference\")\n",
    "    print(f\"Mann-Whitney U statistic: {u_stat}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "    print(f\"Significant (p < 0.05): {p_value < 0.05}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"RQ1 ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n1. Speed of Spread:\")\n",
    "    print(f\"   - Bot cascades spread {speed_results['velocity_ratio']:.2f}x faster than human cascades\")\n",
    "    \n",
    "    print(\"\\n2. Audience Reach:\")\n",
    "    print(f\"   - Bot cascades reach {reach_results['size_ratio']:.2f}x more users on average\")\n",
    "    \n",
    "    print(\"\\n3. Key Findings:\")\n",
    "    print(\"   - [To be filled after analysis]\")\n",
    "    print(\"\\n4. Implications:\")\n",
    "    print(\"   - [To be filled after analysis]\")\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
